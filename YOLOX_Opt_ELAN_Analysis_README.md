# YOLOX Opt ELAN æ¨¡å‹åˆ†æèˆ‡ PyTorch Backend æ¸…ç†

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æª”è©³ç´°åˆ†æäº† YOLOX Opt ELAN æ¨¡å‹çš„çµæ§‹ã€è¼¸å‡ºæ ¼å¼ã€è¨“ç·´èˆ‡æ¨ç†å·®ç•°ï¼Œä»¥åŠ PyTorch Backend ä»£ç¢¼çš„æ¸…ç†éç¨‹ã€‚

## ğŸ¯ YOLOX Opt ELAN æ¨¡å‹çµæ§‹

### æ¨¡å‹çµ„ä»¶
- **Backbone**: ELAN-Darknet
- **Neck**: YOLOX-PAFPN with ELAN blocks  
- **Head**: YOLOXHead
- **Input Size**: 960x960
- **Classes**: 8 å€‹äº¤é€šç‰©é«”é¡åˆ¥

### é¡åˆ¥å®šç¾©
1. unknown
2. car
3. truck
4. bus
5. trailer
6. motorcycle
7. pedestrian
8. bicycle

## ğŸ” æ¨¡å‹è¼¸å‡ºçµæ§‹åˆ†æ

### Tuple è¼¸å‡ºæ ¼å¼ (3 å€‹å…ƒç´ )

YOLOX Opt ELAN æ¨¡å‹çš„ `bbox_head.forward()` è¿”å›åŒ…å« **3 å€‹å…ƒç´ ** çš„ tupleï¼š

```python
cls_scores, bbox_preds, objectnesses = self.bbox_head(feat)
```

#### 1. cls_scores (List[Tensor]) - åˆ†é¡åˆ†æ•¸
- **å½¢ç‹€**: `[batch_size, num_classes, height, width]`
- **å…§å®¹**: æ¯å€‹æª¢æ¸¬å±¤çš„åˆ†é¡é æ¸¬
- **ç¤ºä¾‹**: `torch.Size([1, 8, 120, 120])`, `torch.Size([1, 8, 60, 60])`, `torch.Size([1, 8, 30, 30])`

#### 2. bbox_preds (List[Tensor]) - é‚Šç•Œæ¡†é æ¸¬
- **å½¢ç‹€**: `[batch_size, 4, height, width]`
- **å…§å®¹**: é‚Šç•Œæ¡†å›æ­¸åƒæ•¸ `[dx, dy, dw, dh]`
- **ç¤ºä¾‹**: `torch.Size([1, 4, 120, 120])`, `torch.Size([1, 4, 60, 60])`, `torch.Size([1, 4, 30, 30])`

#### 3. objectnesses (List[Tensor]) - ç›®æ¨™æ€§åˆ†æ•¸
- **å½¢ç‹€**: `[batch_size, 1, height, width]`
- **å…§å®¹**: ç›®æ¨™æ€§é æ¸¬ (æ˜¯å¦åŒ…å«ç‰©é«”)
- **ç¤ºä¾‹**: `torch.Size([1, 1, 120, 120])`, `torch.Size([1, 1, 60, 60])`, `torch.Size([1, 1, 30, 30])`

### æª¢æ¸¬å±¤åˆ†æ

æ¨¡å‹ä½¿ç”¨ **3 å€‹æª¢æ¸¬å±¤** é€²è¡Œå¤šå°ºåº¦æª¢æ¸¬ï¼š

| æª¢æ¸¬å±¤ | è§£æåº¦ | Anchor æ•¸é‡ | ç”¨é€” |
|--------|--------|-------------|------|
| P3 | 120x120 | 14,400 | æª¢æ¸¬å°ç‰©é«” |
| P4 | 60x60 | 3,600 | æª¢æ¸¬ä¸­ç­‰ç‰©é«” |
| P5 | 30x30 | 900 | æª¢æ¸¬å¤§ç‰©é«” |
| **ç¸½è¨ˆ** | - | **18,900** | æ‰€æœ‰æª¢æ¸¬å±¤ |

## ğŸ”„ è¨“ç·´ vs æ¨ç†å·®ç•°

### è¨“ç·´æ™‚ (Training Mode)

**è¼¸å‡ºæ ¼å¼**: åŸå§‹ tuple
```python
cls_scores, bbox_preds, objectnesses = self.bbox_head(feat)
```

**è™•ç†æµç¨‹**:
1. Flatten æ‰€æœ‰æª¢æ¸¬å±¤
2. Concatenate æ‰€æœ‰æª¢æ¸¬å±¤
3. è¨ˆç®— 3 ç¨® loss:
   - `loss_cls`: åˆ†é¡æå¤±
   - `loss_bbox`: é‚Šç•Œæ¡†æå¤±  
   - `loss_obj`: ç›®æ¨™æ€§æå¤±

**Loss è¨ˆç®—ä»£ç¢¼**:
```python
def loss_by_feat(cls_scores, bbox_preds, objectnesses, batch_gt_instances):
    # 1. Flatten æ‰€æœ‰æª¢æ¸¬å±¤
    flatten_cls_preds = [cls_pred.permute(0,2,3,1).reshape(B, -1, 8) for cls_pred in cls_scores]
    flatten_bbox_preds = [bbox_pred.permute(0,2,3,1).reshape(B, -1, 4) for bbox_pred in bbox_preds]
    flatten_objectness = [obj.permute(0,2,3,1).reshape(B, -1) for obj in objectnesses]
    
    # 2. Concatenate æ‰€æœ‰æª¢æ¸¬å±¤
    flatten_cls_preds = torch.cat(flatten_cls_preds, dim=1)      # [B, 18900, 8]
    flatten_bbox_preds = torch.cat(flatten_bbox_preds, dim=1)     # [B, 18900, 4]
    flatten_objectness = torch.cat(flatten_objectness, dim=1)     # [B, 18900]
    
    # 3. è§£ç¢¼é‚Šç•Œæ¡†
    flatten_bboxes = self._bbox_decode(flatten_priors, flatten_bbox_preds)
    
    # 4. è¨ˆç®— 3 ç¨® loss
    loss_obj = self.loss_obj(flatten_objectness, obj_targets)
    loss_cls = self.loss_cls(flatten_cls_preds[pos_masks], cls_targets)
    loss_bbox = self.loss_bbox(flatten_bboxes[pos_masks], bbox_targets)
    
    return dict(loss_cls=loss_cls, loss_bbox=loss_bbox, loss_obj=loss_obj)
```

### æ¨ç†æ™‚ (Inference Mode)

**è¼¸å‡ºæ ¼å¼**: å¾Œè™•ç†çµæœ
```python
result_list = [
    InstanceData(
        bboxes=tensor([[x1, y1, x2, y2], ...]),      # è§£ç¢¼å¾Œçš„é‚Šç•Œæ¡†
        scores=tensor([0.95, 0.87, 0.76, ...]),       # æœ€çµ‚åˆ†æ•¸
        labels=tensor([1, 2, 0, ...])                 # é¡åˆ¥æ¨™ç±¤
    ),
    # ... æ›´å¤šåœ–åƒçš„çµæœ
]
```

**è™•ç†æµç¨‹**:
1. Flatten å’Œ concatenate æª¢æ¸¬å±¤
2. æ‡‰ç”¨ sigmoid æ¿€æ´»
3. è§£ç¢¼é‚Šç•Œæ¡†
4. NMS å’Œé–¾å€¼éæ¿¾
5. è¿”å›æœ€çµ‚æª¢æ¸¬çµæœ

### ONNX Wrapper è™•ç†

**è¼¸å‡ºæ ¼å¼**: `[batch_size, 18900, 13]`
```python
# æ ¼å¼: [bbox_reg(4), objectness(1), class_scores(8)]
# å…¶ä¸­ 13 = 4 + 1 + 8
```

**è™•ç†ä»£ç¢¼**:
```python
def forward(self, x: torch.Tensor) -> torch.Tensor:
    # 1. ç‰¹å¾µæå–
    feat = self.model.extract_feat(x)
    
    # 2. Head è¼¸å‡º
    cls_scores, bbox_preds, objectnesses = self.bbox_head(feat)
    
    # 3. è™•ç†æ¯å€‹æª¢æ¸¬å±¤
    outputs = []
    for cls_score, bbox_pred, objectness in zip(cls_scores, bbox_preds, objectnesses):
        # æ‡‰ç”¨ sigmoid åˆ° objectness å’Œ cls_score (NOT bbox_pred)
        output = torch.cat([bbox_pred, objectness.sigmoid(), cls_score.sigmoid()], 1)
        outputs.append(output)
    
    # 4. Flatten å’Œ concatenate æ‰€æœ‰å±¤
    batch_size = outputs[0].shape[0]
    num_channels = outputs[0].shape[1]
    outputs = torch.cat([x.reshape(batch_size, num_channels, -1) for x in outputs], dim=2).permute(0, 2, 1)
    
    return outputs  # [B, 18900, 13]
```

## ğŸ§¹ PyTorch Backend ä»£ç¢¼æ¸…ç†

### æ¸…ç†å‰çš„å•é¡Œ

1. **éåº¦è¤‡é›œçš„ if-else èªå¥** (200+ è¡Œ)
2. **æ··åˆé—œæ³¨é»** - æ‰€æœ‰é‚è¼¯éƒ½åœ¨ä¸€å€‹æ–¹æ³•ä¸­
3. **é‡è¤‡çš„ä»£ç¢¼** - ç›¸ä¼¼çš„ tensor è½‰æ›é‚è¼¯
4. **éå¤šçš„ debug æ—¥èªŒ** - å½±éŸ¿å¯è®€æ€§
5. **ç¼ºä¹æ¨¡çµ„åŒ–** - é›£ä»¥ç¶­è­·å’Œæ¸¬è©¦

### æ¸…ç†å¾Œçš„æ”¹é€²

#### 1. æå–è¤‡é›œé‚è¼¯åˆ°å°ˆé–€æ–¹æ³•

**ä¸»è¦æ–¹æ³•**:
- `_process_model_output()` - ä¸»è¦è¼¸å‡ºè™•ç†å”èª¿å™¨
- `_extract_2d_predictions()` - è™•ç† 2D æª¢æ¸¬è¼¸å‡º
- `_extract_3d_predictions()` - è™•ç† 3D æª¢æ¸¬è¼¸å‡º
- `_process_list_output()` - è™•ç†åˆ—è¡¨é¡å‹è¼¸å‡º
- `_convert_to_tensor()` - é›†ä¸­åŒ– tensor è½‰æ›é‚è¼¯
- `_extract_yolox_raw_output()` - YOLOX ç‰¹å®šè™•ç†
- `_convert_to_numpy()` - è½‰æ›ç‚º numpy æ•¸çµ„

#### 2. ç°¡åŒ–ä¸» `infer()` æ–¹æ³•

**æ¸…ç†å‰**: ~200 è¡Œè¤‡é›œé‚è¼¯
**æ¸…ç†å¾Œ**: ~30 è¡Œæ¸…æ™°æµç¨‹

```python
def infer(self, input_tensor: torch.Tensor) -> Tuple[np.ndarray, float]:
    """Run inference on input tensor."""
    if not self.is_loaded:
        raise RuntimeError("Model not loaded. Call load_model() first.")

    # Move input to correct device
    input_tensor = input_tensor.to(self._torch_device)

    # Run inference with timing
    with torch.no_grad():
        start_time = time.perf_counter()
        output = self._model(input_tensor)
        end_time = time.perf_counter()

    latency_ms = (end_time - start_time) * 1000

    # Process output based on model type and format
    output = self._process_model_output(output, input_tensor)
    
    # Convert to numpy array
    output_array = self._convert_to_numpy(output)
    
    return output_array, latency_ms
```

#### 3. æ¶ˆé™¤æ·±åº¦åµŒå¥—

**æ¸…ç†å‰**: å¤šå±¤åµŒå¥—çš„ if-else èªå¥
**æ¸…ç†å¾Œ**: æ¯å€‹æ–¹æ³•å–®ä¸€è·è²¬ï¼Œæ¸…æ™°çš„æ¢ä»¶è™•ç†

#### 4. ç§»é™¤éåº¦æ—¥èªŒ

**æ¸…ç†å‰**: 10+ å€‹ debug æ—¥èªŒèªå¥
**æ¸…ç†å¾Œ**: ä¿ç•™å¿…è¦åŠŸèƒ½ï¼Œç§»é™¤å†—é¤˜æ—¥èªŒ

### æ¸…ç†æ•ˆæœ

| æŒ‡æ¨™ | æ¸…ç†å‰ | æ¸…ç†å¾Œ | æ”¹é€² |
|------|--------|--------|------|
| **ä¸»æ–¹æ³•è¡Œæ•¸** | ~200 | ~30 | 85% æ¸›å°‘ |
| **æ–¹æ³•æ•¸é‡** | 1 | 8 | æ¨¡çµ„åŒ– |
| **åµŒå¥—å±¤ç´š** | 5+ | 2-3 | ç°¡åŒ– |
| **å¯è®€æ€§** | ä½ | é«˜ | é¡¯è‘—æå‡ |
| **å¯ç¶­è­·æ€§** | ä½ | é«˜ | é¡¯è‘—æå‡ |
| **å¯æ¸¬è©¦æ€§** | ä½ | é«˜ | é¡¯è‘—æå‡ |

## ğŸ”§ é—œéµæ–¹æ³•ä½ç½®

### extract_feat() æ–¹æ³•

**ä½ç½®**: `mmdetection/mmdet/models/detectors/single_stage.py` (ç¬¬ 136-149 è¡Œ)

**ç¹¼æ‰¿é—œä¿‚**:
```
YOLOX â†’ SingleStageDetector â†’ BaseDetector
```

**å¯¦ç¾**:
```python
def extract_feat(self, batch_inputs: Tensor) -> Tuple[Tensor]:
    """Extract features."""
    x = self.backbone(batch_inputs)  # é€šé backbone æå–ç‰¹å¾µ
    if self.with_neck:
        x = self.neck(x)             # é€šé neck é€²ä¸€æ­¥è™•ç†
    return x
```

## ğŸ“Š æ¸¬è©¦èˆ‡è©•ä¼°

### æ¸¬è©¦å‘½ä»¤

```bash
# æ¨™æº–æ¸¬è©¦
python tools/detection2d/test.py \
    projects/YOLOX_opt_elan/configs/t4dataset/yolox-s-opt-elan_960x960_300e_t4dataset.py \
    /workspace/work_dirs/yolox-s-opt-elan_960x960_300e_t4dataset/epoch_300.pth

# éƒ¨ç½²æ¸¬è©¦
python projects/YOLOX_opt_elan/deploy/main.py \
    projects/YOLOX_opt_elan/deploy/deploy_config.py \
    projects/YOLOX_opt_elan/configs/t4dataset/YOLOX_opt-S-DynamicRecognition/yolox-s-opt-elan_960x960_300e_t4dataset.py \
    path/to/checkpoint.pth \
    --work-dir work_dirs/yolox_opt_elan_deployment
```

### æ€§èƒ½æŒ‡æ¨™

- **mAP@50**: 0.6481 (èˆ‡ test.py çµæœä¸€è‡´)
- **å»¶é²**: < 10ms (Xavier GPU)
- **DLA å»¶é²**: 16ms (YOLOX-s å„ªåŒ–æ¨¡å‹)

## ğŸ¯ ç¸½çµ

### é—œéµè¦é»

1. **YOLOX Opt ELAN è¼¸å‡º**: 3 å€‹æª¢æ¸¬å±¤çš„ tupleï¼ŒåŒ…å«åˆ†é¡ã€é‚Šç•Œæ¡†å’Œç›®æ¨™æ€§åˆ†æ•¸
2. **è¨“ç·´ vs æ¨ç†**: è¨“ç·´æ™‚ä¿æŒåŸå§‹æ ¼å¼è¨ˆç®— lossï¼Œæ¨ç†æ™‚é€²è¡Œå¾Œè™•ç†
3. **ONNX å°å‡º**: é€šé wrapper å°‡ tuple è½‰æ›ç‚º `[B, 18900, 13]` æ ¼å¼
4. **ä»£ç¢¼æ¸…ç†**: å°‡è¤‡é›œé‚è¼¯åˆ†è§£ç‚ºå°ˆé–€æ–¹æ³•ï¼Œæé«˜å¯ç¶­è­·æ€§

### æœ€ä½³å¯¦è¸

1. **æ¨¡çµ„åŒ–è¨­è¨ˆ**: æ¯å€‹æ–¹æ³•å–®ä¸€è·è²¬
2. **æ¸…æ™°çš„åˆ†é›¢**: è¨“ç·´å’Œæ¨ç†é‚è¼¯åˆ†é›¢
3. **é©ç•¶çš„æŠ½è±¡**: é¿å…éåº¦åµŒå¥—
4. **æ–‡æª”å®Œæ•´**: æ¯å€‹æ–¹æ³•éƒ½æœ‰æ¸…æ™°çš„æ–‡æª”

é€™å€‹åˆ†æç‚ºç†è§£ YOLOX Opt ELAN æ¨¡å‹çš„å…§éƒ¨å·¥ä½œåŸç†å’Œ PyTorch Backend çš„å„ªåŒ–æä¾›äº†å®Œæ•´çš„æŒ‡å—ã€‚
