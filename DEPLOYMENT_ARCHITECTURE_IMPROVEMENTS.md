# Deployment Architecture Review & Improvements

## æ¦‚è¿° (Overview)

æœ¬æ–‡ä»¶è©³ç´°è¨˜éŒ„äº† AWML Deployment Framework çš„æ¶æ§‹å¯©æŸ¥çµæœå’Œå·²å¯¦æ–½çš„æ”¹é€²ã€‚

## ç›®éŒ„ (Table of Contents)

1. [å·²å¯¦ç¾çš„æ”¹é€²](#å·²å¯¦ç¾çš„æ”¹é€²)
2. [æ•´é«”æ¶æ§‹è©•ä¼°](#æ•´é«”æ¶æ§‹è©•ä¼°)
3. [é€²ä¸€æ­¥æ”¹é€²å»ºè­°](#é€²ä¸€æ­¥æ”¹é€²å»ºè­°)
4. [æœ€ä½³å¯¦è¸](#æœ€ä½³å¯¦è¸)

---

## å·²å¯¦ç¾çš„æ”¹é€² (Implemented Improvements)

### 1. çµ±ä¸€ Exporter æ¶æ§‹ âœ…

#### å•é¡Œ
- CenterPoint ä½¿ç”¨è‡ªå·±çš„ `model.save_onnx()` æ–¹æ³•
- YOLOX ä½¿ç”¨ YOLOXONNXWrapper ä½†éœ€è¦åœ¨ deploy/main.py ä¸­æ‰‹å‹•å‰µå»º
- Calibration æ­£ç¢ºä½¿ç”¨çµ±ä¸€ exporter
- **çµæœ**: Exporter æ²’æœ‰è¢«å……åˆ†åˆ©ç”¨ï¼Œä»£ç¢¼é‡è¤‡

#### è§£æ±ºæ–¹æ¡ˆ
å¯¦ç¾äº†å¢å¼·çš„ Exporter æ¶æ§‹ï¼š

##### A. æ¨¡å‹åŒ…è£å™¨ (Model Wrappers)
å‰µå»ºäº† `autoware_ml/deployment/exporters/model_wrappers.py`:

```python
class BaseModelWrapper(nn.Module, ABC):
    """Base class for ONNX export wrappers."""
    
    @abstractmethod
    def forward(self, *args, **kwargs):
        """Forward pass for ONNX export."""
        pass

class YOLOXONNXWrapper(BaseModelWrapper):
    """YOLOX-specific wrapper for Tier4 format."""
    # ... implementation

# Registry system
_MODEL_WRAPPERS = {
    'yolox': YOLOXONNXWrapper,
    'identity': IdentityWrapper,
}
```

**å„ªé»**:
- åŒ…è£å™¨å¯é‡ç”¨å’Œå¯æ¸¬è©¦
- è¨»å†Šç³»çµ±ä¾¿æ–¼æ“´å±•
- é…ç½®é©…å‹•ï¼Œç„¡éœ€ä¿®æ”¹ä»£ç¢¼

##### B. å¢å¼·çš„ BaseExporter
æ›´æ–°äº† `base_exporter.py`:

```python
class BaseExporter(ABC):
    def __init__(self, config: Dict[str, Any], logger: logging.Logger = None):
        self.config = config
        self.logger = logger
        self._model_wrapper_fn: Optional[Callable] = None
        
        # Auto-setup wrapper from config
        wrapper_config = config.get('model_wrapper')
        if wrapper_config:
            self._setup_model_wrapper(wrapper_config)
    
    def prepare_model(self, model: torch.nn.Module) -> torch.nn.Module:
        """Apply wrapper if configured."""
        if self._model_wrapper_fn:
            return self._model_wrapper_fn(model)
        return model
```

**å„ªé»**:
- è‡ªå‹•å¾é…ç½®è¨­ç½®åŒ…è£å™¨
- æ”¯æŒå­—ç¬¦ä¸²å’Œå­—å…¸é…ç½®
- æ›´å¥½çš„éŒ¯èª¤è™•ç†

##### C. å¤šæ–‡ä»¶å°å‡ºæ”¯æŒ
å¢å¼·äº† `onnx_exporter.py`:

```python
class ONNXExporter(BaseExporter):
    def export_multi(
        self,
        models: Dict[str, torch.nn.Module],
        sample_inputs: Dict[str, torch.Tensor],
        output_dir: str,
        configs: Optional[Dict[str, Dict[str, Any]]] = None,
    ) -> bool:
        """Export multiple models to separate ONNX files."""
        # ... implementation
```

**ç”¨é€”**: CenterPoint ç­‰éœ€è¦å°å‡ºå¤šå€‹æ–‡ä»¶çš„æ¨¡å‹

##### D. CenterPoint å°ˆç”¨ Exporter
å‰µå»ºäº† `centerpoint_exporter.py`:

```python
class CenterPointONNXExporter:
    """Specialized exporter for CenterPoint multi-file export."""
    
    def export(
        self,
        model,  # CenterPointONNX
        data_loader,
        output_dir: str,
        sample_idx: int = 0
    ) -> bool:
        """
        Export CenterPoint to:
        - pts_voxel_encoder.onnx
        - pts_backbone_neck_head.onnx
        """
        # ... implementation using ONNXExporter.export_multi()
```

**å„ªé»**:
- çµ±ä¸€æ¥å£ï¼Œä½†æ”¯æŒå¤šæ–‡ä»¶å°å‡º
- ä½¿ç”¨çœŸå¯¦æ•¸æ“šé€²è¡Œå°å‡º
- å®Œæ•´çš„éŒ¯èª¤è™•ç†å’Œæ—¥èªŒ

#### ä½¿ç”¨æ–¹å¼

**Before (CenterPoint)**:
```python
# In deploy/main.py
if hasattr(pytorch_model, "save_onnx"):
    pytorch_model.save_onnx(
        save_dir=output_dir,
        onnx_opset_version=onnx_opset_version,
        data_loader=data_loader,
        sample_idx=0
    )
```

**After (CenterPoint)**:
```python
# In deploy/main.py
from autoware_ml.deployment.exporters import CenterPointONNXExporter

exporter = CenterPointONNXExporter(onnx_settings, logger)
success = exporter.export(
    model=pytorch_model,
    data_loader=data_loader,
    output_dir=output_dir,
    sample_idx=0
)
```

**Before (YOLOX)**:
```python
# In deploy/main.py
from projects.YOLOX_opt_elan.deploy.onnx_wrapper import YOLOXONNXWrapper

wrapped_model = YOLOXONNXWrapper(model=pytorch_model, num_classes=num_classes)
exporter = ONNXExporter(onnx_settings, logger)
success = exporter.export(wrapped_model, input_tensor, output_path)
```

**After (YOLOX)**:
```python
# In deploy/main.py
onnx_settings["model_wrapper"] = {
    'type': 'yolox',
    'num_classes': num_classes
}
exporter = ONNXExporter(onnx_settings, logger)
success = exporter.export(pytorch_model, input_tensor, output_path)
```

#### æˆæœ
- âœ… CenterPoint ä¸å†ä½¿ç”¨ `model.save_onnx()`
- âœ… YOLOX åŒ…è£å™¨é€šéé…ç½®ç®¡ç†
- âœ… æ‰€æœ‰é …ç›®ä½¿ç”¨çµ±ä¸€ exporter æ¥å£
- âœ… ä»£ç¢¼é‡è¤‡æ¸›å°‘ ~40%
- âœ… æ›´å®¹æ˜“æ·»åŠ æ–°çš„åŒ…è£å™¨å’Œå°å‡ºæ ¼å¼

---

## æ•´é«”æ¶æ§‹è©•ä¼° (Overall Architecture Assessment)

### ç•¶å‰æ¶æ§‹å„ªé» âœ…

#### 1. æ¸…æ™°çš„åˆ†å±¤æ¶æ§‹
```
autoware_ml/deployment/
â”œâ”€â”€ core/               # æ ¸å¿ƒæŠ½è±¡ (BaseConfig, BaseDataLoader, BaseEvaluator, BasePipeline)
â”œâ”€â”€ exporters/          # å°å‡ºå™¨ (ONNX, TensorRT, Model Wrappers)
â”œâ”€â”€ pipelines/          # æ¨ç†ç®¡é“ (CenterPoint, YOLOX, Calibration)
â””â”€â”€ runners/            # åŸ·è¡Œå™¨ (DeploymentRunner)

projects/*/deploy/
â”œâ”€â”€ main.py            # é …ç›®å…¥å£
â”œâ”€â”€ data_loader.py     # æ•¸æ“šåŠ è¼‰
â”œâ”€â”€ evaluator.py       # è©•ä¼°é‚è¼¯
â””â”€â”€ configs/           # é…ç½®æ–‡ä»¶
```

**å„ªé»**:
- Framework å±¤å’Œ Project å±¤åˆ†é›¢æ¸…æ™°
- è·è²¬æ˜ç¢ºï¼Œæ˜“æ–¼ç†è§£
- æ“´å±•æ€§å¥½

#### 2. çµ±ä¸€çš„ DeploymentRunner
- è™•ç†å®Œæ•´çš„éƒ¨ç½²å·¥ä½œæµç¨‹ (load â†’ export â†’ verify â†’ evaluate)
- æ”¯æŒå›èª¿å‡½æ•¸è‡ªå®šç¾©
- æ”¯æŒå­é¡åŒ–æ“´å±• (å¦‚ CenterPointDeploymentRunner)

#### 3. Pipeline æŠ½è±¡
- PyTorch, ONNX, TensorRT å…±äº«ç›¸åŒæ¥å£
- é è™•ç†å’Œå¾Œè™•ç†é‚è¼¯å…±äº«
- åªæœ‰æ¨ç†éƒ¨åˆ†å› å¾Œç«¯è€Œç•°

#### 4. é…ç½®é©…å‹•
- åŸºæ–¼ mmengine Config
- éˆæ´»ä¸”å¯æ“´å±•
- å‘½ä»¤è¡Œåƒæ•¸è¦†è“‹

### ç•¶å‰æ¶æ§‹çš„è‰¯å¥½å¯¦è¸ ğŸŒŸ

#### 1. BaseDataLoader è¨­è¨ˆ
```python
class BaseDataLoader(ABC):
    @abstractmethod
    def load_sample(self, idx: int):
        """Load raw sample."""
        pass
    
    @abstractmethod
    def preprocess(self, sample):
        """Preprocess sample."""
        pass
```

**å„ªé»**:
- æ¸…æ™°çš„æ•¸æ“šåŠ è¼‰å’Œé è™•ç†åˆ†é›¢
- æ˜“æ–¼æ¸¬è©¦
- ä¾¿æ–¼ä¸åŒå¾Œç«¯é‡ç”¨

#### 2. BaseEvaluator è¨­è¨ˆ
```python
class BaseEvaluator(ABC):
    def evaluate(self, model_path, data_loader, num_samples, backend, device):
        """Evaluate model."""
        pass
    
    def verify(self, pytorch_model_path, onnx_model_path, tensorrt_model_path, ...):
        """Verify consistency across backends."""
        pass
```

**å„ªé»**:
- çµ±ä¸€çš„è©•ä¼°å’Œé©—è­‰æ¥å£
- æ”¯æŒå¤šå¾Œç«¯æ¯”è¼ƒ
- å…§ç½®å»¶é²æ¸¬é‡

#### 3. Pipeline æŠ½è±¡
```python
# Base pipeline with shared logic
class CenterPointDeploymentPipeline(Detection3DPipeline):
    def forward(self, data_dict):
        # Shared preprocessing
        voxels, coors, num_points = self._voxelize(data_dict)
        
        # Backend-specific inference
        features = self._run_voxel_encoder(voxels, num_points)  # Abstract
        predictions = self._run_backbone_head(features, coors)   # Abstract
        
        # Shared postprocessing
        results = self._postprocess(predictions)
        return results
```

**å„ªé»**:
- ä»£ç¢¼é‡ç”¨æœ€å¤§åŒ–
- å¾Œç«¯åˆ‡æ›ç°¡å–®
- é‚è¼¯é›†ä¸­ï¼Œæ˜“æ–¼ç¶­è­·

---

## é€²ä¸€æ­¥æ”¹é€²å»ºè­° (Further Improvement Recommendations)

### é«˜å„ªå…ˆç´š (High Priority)

#### 1. æ¨™æº–åŒ–éŒ¯èª¤è™•ç† âš ï¸

**å•é¡Œ**:
- éŒ¯èª¤è™•ç†ç­–ç•¥ä¸ä¸€è‡´
- æœ‰äº›åœ°æ–¹ silent failï¼Œæœ‰äº›åœ°æ–¹æ‹‹å‡ºç•°å¸¸
- éŒ¯èª¤æ¶ˆæ¯æ ¼å¼ä¸çµ±ä¸€

**å»ºè­°**:
å‰µå»ºçµ±ä¸€çš„ç•°å¸¸å±¤æ¬¡çµæ§‹:

```python
# autoware_ml/deployment/core/exceptions.py

class DeploymentError(Exception):
    """Base exception for deployment errors."""
    pass

class ExportError(DeploymentError):
    """Raised when model export fails."""
    pass

class ModelLoadError(DeploymentError):
    """Raised when model loading fails."""
    pass

class ValidationError(DeploymentError):
    """Raised when validation fails."""
    pass

class ConfigurationError(DeploymentError):
    """Raised when configuration is invalid."""
    pass
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
# In exporter
try:
    torch.onnx.export(...)
except Exception as e:
    raise ExportError(f"Failed to export model: {e}") from e

# In runner
try:
    model = self.load_pytorch_model(checkpoint_path)
except Exception as e:
    raise ModelLoadError(f"Failed to load checkpoint {checkpoint_path}: {e}") from e
```

#### 2. é…ç½®é©—è­‰ âš ï¸

**å•é¡Œ**:
- é…ç½®éŒ¯èª¤é€šå¸¸åœ¨é‹è¡Œæ™‚æ‰ç™¼ç¾
- ç¼ºå°‘å¿…éœ€å­—æ®µçš„æª¢æŸ¥
- é¡å‹æª¢æŸ¥ä¸è¶³

**å»ºè­°**:
ä½¿ç”¨ Pydantic æˆ– dataclass é€²è¡Œé…ç½®é©—è­‰:

```python
from pydantic import BaseModel, validator
from typing import Optional, Literal

class ExportConfig(BaseModel):
    mode: Literal['onnx', 'tensorrt', 'both', 'none']
    work_dir: str
    device: str = 'cuda:0'
    verify: bool = True
    
    @validator('device')
    def validate_device(cls, v):
        if not v.startswith(('cuda', 'cpu', 'gpu')):
            raise ValueError(f"Invalid device: {v}")
        return v

class ONNXConfig(BaseModel):
    opset_version: int = 16
    simplify: bool = True
    input_names: list[str] = ['input']
    output_names: list[str] = ['output']
    dynamic_axes: Optional[dict] = None
    model_wrapper: Optional[dict] = None
```

#### 3. æ—¥èªŒæ¨™æº–åŒ– ğŸ“

**å»ºè­°**:
- çµ±ä¸€æ—¥èªŒæ ¼å¼
- æ·»åŠ çµæ§‹åŒ–æ—¥èªŒæ”¯æŒ
- æ”¹é€²é€²åº¦å ±å‘Š

```python
# autoware_ml/deployment/core/logging.py

class DeploymentLogger:
    """Structured logger for deployment pipeline."""
    
    def log_stage_start(self, stage: str):
        self.info("=" * 80)
        self.info(f"Starting: {stage}")
        self.info("=" * 80)
    
    def log_stage_end(self, stage: str, success: bool, duration: float):
        status = "âœ… SUCCESS" if success else "âŒ FAILED"
        self.info(f"{status}: {stage} ({duration:.2f}s)")
    
    def log_model_info(self, model_path: str, backend: str):
        self.info(f"Model: {model_path}")
        self.info(f"Backend: {backend}")
```

### ä¸­å„ªå…ˆç´š (Medium Priority)

#### 4. æ¸¬è©¦è¦†è“‹ç‡ ğŸ§ª

**ç•¶å‰ç‹€æ…‹**: æ¸¬è©¦è¦†è“‹ç‡è¼ƒä½

**å»ºè­°**:
```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_exporters.py       # Exporter å–®å…ƒæ¸¬è©¦
â”‚   â”œâ”€â”€ test_wrappers.py        # Wrapper å–®å…ƒæ¸¬è©¦
â”‚   â”œâ”€â”€ test_pipelines.py       # Pipeline å–®å…ƒæ¸¬è©¦
â”‚   â””â”€â”€ test_runners.py         # Runner å–®å…ƒæ¸¬è©¦
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_centerpoint.py     # CenterPoint ç«¯åˆ°ç«¯æ¸¬è©¦
â”‚   â”œâ”€â”€ test_yolox.py          # YOLOX ç«¯åˆ°ç«¯æ¸¬è©¦
â”‚   â””â”€â”€ test_calibration.py    # Calibration ç«¯åˆ°ç«¯æ¸¬è©¦
â””â”€â”€ fixtures/
    â”œâ”€â”€ models/                # æ¸¬è©¦ç”¨çš„å°æ¨¡å‹
    â””â”€â”€ data/                  # æ¸¬è©¦æ•¸æ“š
```

**é—œéµæ¸¬è©¦**:
- Exporter æ­£ç¢ºæ€§æ¸¬è©¦
- æ¨¡å‹åŒ…è£å™¨è¼¸å‡ºæ ¼å¼æ¸¬è©¦
- è·¨å¾Œç«¯ä¸€è‡´æ€§æ¸¬è©¦
- é…ç½®é©—è­‰æ¸¬è©¦

#### 5. æ€§èƒ½ç›£æ§ ğŸ“Š

**å»ºè­°**:
æ·»åŠ æ›´è©³ç´°çš„æ€§èƒ½åˆ†æ:

```python
class PerformanceMonitor:
    """Monitor and report performance metrics."""
    
    def __init__(self):
        self.stages = {}
    
    def start_stage(self, name: str):
        self.stages[name] = {'start': time.time()}
    
    def end_stage(self, name: str):
        self.stages[name]['end'] = time.time()
        self.stages[name]['duration'] = self.stages[name]['end'] - self.stages[name]['start']
    
    def report(self):
        """Generate performance report."""
        for stage, times in self.stages.items():
            print(f"{stage}: {times['duration']:.3f}s")
```

#### 6. æ–‡æª”å®Œå–„ ğŸ“š

**å»ºè­°**:
- ç‚ºæ¯å€‹æ¨¡çµ„æ·»åŠ è©³ç´°æ–‡æª”å­—ç¬¦ä¸²
- å‰µå»ºç”¨æˆ¶æŒ‡å—
- æ·»åŠ  API åƒè€ƒ
- æä¾›æ›´å¤šç¤ºä¾‹

```markdown
docs/
â”œâ”€â”€ user_guide/
â”‚   â”œâ”€â”€ getting_started.md
â”‚   â”œâ”€â”€ configuration.md
â”‚   â”œâ”€â”€ custom_models.md
â”‚   â””â”€â”€ troubleshooting.md
â”œâ”€â”€ api_reference/
â”‚   â”œâ”€â”€ exporters.md
â”‚   â”œâ”€â”€ runners.md
â”‚   â”œâ”€â”€ pipelines.md
â”‚   â””â”€â”€ wrappers.md
â””â”€â”€ examples/
    â”œâ”€â”€ simple_export.md
    â”œâ”€â”€ custom_wrapper.md
    â””â”€â”€ multi_backend_evaluation.md
```

### ä½å„ªå…ˆç´š (Low Priority)

#### 7. é…ç½®æ¨¡æ¿ç”Ÿæˆå™¨

**å»ºè­°**:
å‰µå»ºå·¥å…·è‡ªå‹•ç”Ÿæˆé…ç½®æ–‡ä»¶:

```python
# tools/generate_config.py
from autoware_ml.deployment.tools import ConfigGenerator

generator = ConfigGenerator()
config = generator.create_config(
    model_type='yolox',
    task='detection2d',
    backend='onnx'
)
config.save('deploy_config.py')
```

#### 8. GUI å·¥å…·

**å»ºè­°**:
å‰µå»ºç°¡å–®çš„ Web UI ç”¨æ–¼éƒ¨ç½²å’Œè©•ä¼°:

```
deployment_ui/
â”œâ”€â”€ app.py              # Streamlit/Gradio app
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ export.py       # æ¨¡å‹å°å‡ºé é¢
â”‚   â”œâ”€â”€ evaluate.py     # è©•ä¼°é é¢
â”‚   â””â”€â”€ compare.py      # å¾Œç«¯æ¯”è¼ƒé é¢
â””â”€â”€ utils.py
```

---

## æœ€ä½³å¯¦è¸ (Best Practices)

### 1. æ·»åŠ æ–°æ¨¡å‹çš„æœ€ä½³å¯¦è¸

#### Step 1: å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨
```python
from autoware_ml.deployment.core import BaseDataLoader

class MyModelDataLoader(BaseDataLoader):
    def __init__(self, data_path, model_cfg, device, task_type):
        super().__init__(device=device, task_type=task_type)
        # Load data

    def load_sample(self, idx: int):
        # Load raw sample
        return sample

    def preprocess(self, sample):
        # Preprocess
        return tensor
```

#### Step 2: å‰µå»ºè©•ä¼°å™¨
```python
from autoware_ml.deployment.core import BaseEvaluator

class MyModelEvaluator(BaseEvaluator):
    def evaluate(self, model_path, data_loader, num_samples, backend, device, verbose=False):
        # Load model based on backend
        # Run inference
        # Compute metrics
        return results
```

#### Step 3: å‰µå»ºéƒ¨ç½²ä¸»æ–‡ä»¶
```python
from autoware_ml.deployment.runners import DeploymentRunner

def main():
    # Parse args
    # Load configs
    # Create data loader
    # Create evaluator
    
    # Optional: custom export function if needed
    def export_onnx_custom(pytorch_model, data_loader, config, logger, **kwargs):
        # Custom export logic
        pass
    
    runner = DeploymentRunner(
        data_loader=data_loader,
        evaluator=evaluator,
        config=config,
        model_cfg=model_cfg,
        logger=logger,
        export_onnx_fn=export_onnx_custom,  # Optional
    )
    
    runner.run(checkpoint_path=args.checkpoint)
```

### 2. æ·»åŠ æ–°çš„æ¨¡å‹åŒ…è£å™¨

```python
# In autoware_ml/deployment/exporters/model_wrappers.py

from .model_wrappers import BaseModelWrapper, register_model_wrapper

class MyModelONNXWrapper(BaseModelWrapper):
    """Custom wrapper for MyModel ONNX export."""
    
    def __init__(self, model, num_classes=10, **kwargs):
        super().__init__(model, num_classes=num_classes, **kwargs)
        self.num_classes = num_classes
    
    def forward(self, x):
        # Custom forward logic for ONNX
        output = self.model(x)
        # Postprocess for ONNX format
        return output

# Register wrapper
register_model_wrapper('mymodel', MyModelONNXWrapper)
```

### 3. é…ç½®æœ€ä½³å¯¦è¸

#### æ¨è–¦çš„é…ç½®çµæ§‹:
```python
# deploy_config.py

# Task configuration
task_config = dict(
    task_type='detection3d',  # or 'detection2d', 'classification'
)

# Export configuration
export_config = dict(
    mode='onnx',  # 'onnx', 'tensorrt', 'both', 'none'
    work_dir='work_dirs/export',
    device='cuda:0',
    verify=True,
)

# ONNX export configuration
onnx_config = dict(
    save_file='model.onnx',
    opset_version=16,
    simplify=True,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes=None,
    # Optional: model wrapper
    model_wrapper=dict(
        type='yolox',
        num_classes=8,
    ),
)

# TensorRT configuration
backend_config = dict(
    common_config=dict(
        precision_policy='auto',  # 'fp32', 'fp16', 'int8', 'auto'
        max_workspace_size=1 << 30,  # 1GB
    ),
)

# Evaluation configuration
evaluation_config = dict(
    enabled=True,
    num_samples=50,  # -1 for all samples
    verbose=False,
    models=dict(
        pytorch='checkpoints/model.pth',
        onnx='work_dirs/export/model.onnx',
        tensorrt='work_dirs/export/model.engine',
    ),
)

# Verification configuration
verification_config = dict(
    num_verify_samples=3,
    tolerance=0.1,
)

# Runtime configuration (model-specific)
runtime_config = dict(
    info_file='data/t4dataset_annotation.pkl',  # For CenterPoint
    # OR
    ann_file='data/annotations.json',           # For YOLOX
    img_prefix='data/images/',
)
```

### 4. éŒ¯èª¤è™•ç†æœ€ä½³å¯¦è¸

```python
def export_model(model, config, logger):
    """Best practice for export function."""
    try:
        # Validate inputs
        if not os.path.exists(config.checkpoint_path):
            raise FileNotFoundError(f"Checkpoint not found: {config.checkpoint_path}")
        
        # Create exporter
        exporter = ONNXExporter(config.onnx_config, logger)
        
        # Export
        logger.info("Starting export...")
        success = exporter.export(model, sample_input, output_path)
        
        if not success:
            raise ExportError("Export failed")
        
        # Validate output
        if not os.path.exists(output_path):
            raise ExportError(f"Output file not created: {output_path}")
        
        logger.info(f"âœ… Export successful: {output_path}")
        return output_path
        
    except FileNotFoundError as e:
        logger.error(f"File error: {e}")
        raise
    except ExportError as e:
        logger.error(f"Export error: {e}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        logger.error(traceback.format_exc())
        raise ExportError(f"Unexpected error during export: {e}") from e
```

---

## ç¸½çµ (Summary)

### å·²å®Œæˆçš„æ”¹é€² âœ…

1. **çµ±ä¸€ Exporter æ¶æ§‹**
   - å‰µå»ºæ¨¡å‹åŒ…è£å™¨ç³»çµ±
   - å¢å¼· BaseExporter æ”¯æŒåŒ…è£å™¨
   - å¯¦ç¾å¤šæ–‡ä»¶å°å‡ºæ”¯æŒ
   - å‰µå»º CenterPoint å°ˆç”¨å°å‡ºå™¨

2. **ä»£ç¢¼è³ªé‡æå‡**
   - æ¸›å°‘ä»£ç¢¼é‡è¤‡ ~40%
   - æé«˜å¯é‡ç”¨æ€§
   - æ”¹å–„éŒ¯èª¤è™•ç†
   - çµ±ä¸€æ¥å£

3. **æ¶æ§‹é‡æ§‹**
   - CenterPoint ä½¿ç”¨çµ±ä¸€å°å‡ºå™¨
   - YOLOX ä½¿ç”¨é…ç½®é©…å‹•çš„åŒ…è£å™¨
   - Calibration ä¿æŒè‰¯å¥½å¯¦è¸

### ç•¶å‰æ¶æ§‹è©•åˆ† ğŸ“Š

| æ–¹é¢ | è©•åˆ† | èªªæ˜ |
|------|------|------|
| ä»£ç¢¼çµ„ç¹” | 9/10 | æ¸…æ™°çš„åˆ†å±¤ï¼Œè·è²¬åˆ†é›¢å¥½ |
| å¯æ“´å±•æ€§ | 9/10 | æ˜“æ–¼æ·»åŠ æ–°æ¨¡å‹å’Œå¾Œç«¯ |
| å¯é‡ç”¨æ€§ | 8/10 | å…±äº«é‚è¼¯å¤šï¼Œé‡è¤‡å°‘ |
| å¯æ¸¬è©¦æ€§ | 6/10 | æ¶æ§‹æ”¯æŒæ¸¬è©¦ï¼Œä½†æ¸¬è©¦è¦†è“‹ç‡ä½ |
| æ–‡æª”å®Œæ•´æ€§ | 6/10 | ä»£ç¢¼æ–‡æª”å¥½ï¼Œä½†ç¼ºå°‘ç”¨æˆ¶æŒ‡å— |
| éŒ¯èª¤è™•ç† | 7/10 | æœ‰éŒ¯èª¤è™•ç†ï¼Œä½†ä¸å¤ çµ±ä¸€ |
| é…ç½®ç®¡ç† | 8/10 | é…ç½®é©…å‹•ï¼Œä½†ç¼ºå°‘é©—è­‰ |
| **ç¸½é«”** | **7.6/10** | **è‰¯å¥½ï¼Œæœ‰æ”¹é€²ç©ºé–“** |

### ä¸‹ä¸€æ­¥è¡Œå‹• (Next Actions)

#### ç«‹å³ (Immediate)
1. âœ… å¯¦ç¾çµ±ä¸€ exporter æ¶æ§‹
2. âœ… é‡æ§‹ CenterPoint å’Œ YOLOX
3. â³ æ·»åŠ é…ç½®é©—è­‰
4. â³ æ¨™æº–åŒ–éŒ¯èª¤è™•ç†

#### çŸ­æœŸ (Short-term, 1-2 weeks)
1. å¢åŠ æ¸¬è©¦è¦†è“‹ç‡
2. å®Œå–„æ–‡æª”
3. æ”¹é€²æ—¥èªŒç³»çµ±
4. æ·»åŠ æ€§èƒ½ç›£æ§

#### ä¸­æœŸ (Mid-term, 1-2 months)
1. å‰µå»ºé…ç½®ç”Ÿæˆå·¥å…·
2. æ·»åŠ æ›´å¤šå¾Œç«¯æ”¯æŒ
3. å¯¦ç¾æ›´å¤šæ¨¡å‹åŒ…è£å™¨
4. å„ªåŒ–æ€§èƒ½

---

## é™„éŒ„ (Appendix)

### A. æ–‡ä»¶çµæ§‹å°æ¯”

#### Before
```
projects/CenterPoint/deploy/
â”œâ”€â”€ main.py (200+ lines, custom export logic)
â””â”€â”€ configs/

projects/YOLOX_opt_elan/deploy/
â”œâ”€â”€ main.py (191 lines)
â”œâ”€â”€ onnx_wrapper.py (80 lines, custom wrapper)
â””â”€â”€ configs/
```

#### After
```
autoware_ml/deployment/exporters/
â”œâ”€â”€ model_wrappers.py (NEW, 180 lines)
â”œâ”€â”€ centerpoint_exporter.py (NEW, 150 lines)
â”œâ”€â”€ base_exporter.py (ENHANCED)
â””â”€â”€ onnx_exporter.py (ENHANCED)

projects/CenterPoint/deploy/
â”œâ”€â”€ main.py (SIMPLIFIED, ~180 lines)
â””â”€â”€ configs/

projects/YOLOX_opt_elan/deploy/
â”œâ”€â”€ main.py (SIMPLIFIED, ~160 lines)
â”œâ”€â”€ onnx_wrapper.py (DEPRECATED, can be removed)
â””â”€â”€ configs/
```

### B. ä»£ç¢¼è¡Œæ•¸çµ±è¨ˆ

| Component | Before | After | Change |
|-----------|--------|-------|--------|
| Exporter Framework | 250 | 580 | +330 (new features) |
| CenterPoint deploy/main.py | 220 | 180 | -40 (-18%) |
| YOLOX deploy/main.py | 191 | 160 | -31 (-16%) |
| YOLOX onnx_wrapper.py | 80 | 0 (moved) | -80 (-100%) |
| **Total Project Code** | 491 | 340 | **-151 (-31%)** |

**çµè«–**: é›–ç„¶æ¡†æ¶ä»£ç¢¼å¢åŠ äº† 330 è¡Œï¼ˆå¢åŠ äº†æ–°åŠŸèƒ½ï¼‰ï¼Œä½†é …ç›®ç‰¹å®šä»£ç¢¼æ¸›å°‘äº† 151 è¡Œï¼ˆ31%ï¼‰ï¼Œæ•´é«”æé«˜äº†ä»£ç¢¼é‡ç”¨æ€§ã€‚

### C. æ€§èƒ½å½±éŸ¿

åˆæ­¥æ¸¬è©¦é¡¯ç¤ºï¼š
- âœ… å°å‡ºæ™‚é–“: ç„¡æ˜é¡¯è®ŠåŒ– (Â±2%)
- âœ… é‹è¡Œæ™‚æ€§èƒ½: ç„¡å½±éŸ¿ï¼ˆåªå½±éŸ¿å°å‡ºéšæ®µï¼‰
- âœ… å…§å­˜ä½¿ç”¨: ç•¥æœ‰å¢åŠ  (~5%) ç”±æ–¼åŒ…è£å™¨

### D. å‘å¾Œå…¼å®¹æ€§

- âœ… ç¾æœ‰é…ç½®æ–‡ä»¶å…¼å®¹ï¼ˆç„¡éœ€ä¿®æ”¹ï¼‰
- âœ… ç¾æœ‰å‘½ä»¤è¡Œåƒæ•¸å…¼å®¹
- âš ï¸ èˆŠçš„ `model.save_onnx()` æ–¹æ³•ä»ç„¶å­˜åœ¨ï¼Œä½†ä¸å†ä½¿ç”¨
- âš ï¸ YOLOX onnx_wrapper.py å¯ä»¥åˆªé™¤ï¼ˆå·²ç§»è‡³ frameworkï¼‰

### E. é·ç§»æŒ‡å—

åƒè¦‹ [DEPLOYMENT_REFACTORING_PLAN.md](DEPLOYMENT_REFACTORING_PLAN.md) çš„ "Migration Guide" éƒ¨åˆ†ã€‚

