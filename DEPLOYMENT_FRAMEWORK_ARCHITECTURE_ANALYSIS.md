# AutoWare ML Deployment Framework æ¶æ§‹åˆ†æ

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æª”è©³ç´°åˆ†æ AutoWare ML ä¸­ä¸‰å€‹æ¨¡å‹çš„ deployment æ¶æ§‹ï¼Œè­˜åˆ¥å…±åŒé»å’Œå·®ç•°ï¼Œä¸¦æå‡ºçµ±ä¸€çš„æ¡†æ¶è¨­è¨ˆå»ºè­°ã€‚

**åˆ†æçš„æ¨¡å‹**:
- **CenterPoint**: 3D ç›®æ¨™æª¢æ¸¬ï¼ˆå¤šå¼•æ“ ONNX/TensorRTï¼‰
- **YOLOX**: 2D ç›®æ¨™æª¢æ¸¬ï¼ˆå–®å¼•æ“ + wrapperï¼‰
- **CalibrationStatusClassification**: åˆ†é¡ä»»å‹™ï¼ˆæ¨™æº–å–®å¼•æ“ï¼‰

---

## ğŸ—ï¸ ç•¶å‰æ¶æ§‹åˆ†æ

### 1. CenterPoint æ¶æ§‹

#### æ–‡ä»¶çµæ§‹
```
projects/CenterPoint/deploy/
â”œâ”€â”€ main.py                           # ä¸»ç¨‹åº
â”œâ”€â”€ data_loader.py                    # æ•¸æ“šåŠ è¼‰
â”œâ”€â”€ evaluator.py                      # è©•ä¼°å™¨
â”œâ”€â”€ centerpoint_tensorrt_backend.py   # è‡ªå®šç¾© TensorRT backend
â””â”€â”€ configs/deploy_config.py          # é…ç½®

autoware_ml/deployment/backends/
â””â”€â”€ centerpoint_onnx_helper.py        # ONNX è¼”åŠ©æ¨¡çµ„
```

#### ç‰¹æ®Šéœ€æ±‚
- **å¤šå¼•æ“ ONNX**: `pts_voxel_encoder.onnx` + `pts_backbone_neck_head.onnx`
- **å¤šå¼•æ“ TensorRT**: `pts_voxel_encoder.trt` + `pts_backbone_neck_head.trt`
- **æ··åˆåŸ·è¡Œ**: Middle encoder åœ¨ PyTorch ä¸­é‹è¡Œ
- **è‡ªå®šç¾©å¾Œè™•ç†**: éœ€è¦ PyTorch decoder é€²è¡Œ NMS

#### å¯¦ç¾æ–¹å¼
```python
# 1. è‡ªå®šç¾© ONNX Helper
class CenterPointONNXHelper:
    def preprocess_for_onnx(self, input_data):
        # è™•ç† voxel encoder
        voxel_features = self.voxel_encoder_session.run(...)
        # è™•ç† middle encoder (PyTorch)
        spatial_features = self._process_middle_encoder(...)
        return {"spatial_features": spatial_features}

# 2. è‡ªå®šç¾© TensorRT Backend
class CenterPointTensorRTBackend:
    def infer(self, input_data):
        # é‹è¡Œ voxel encoder
        voxel_features = self._run_voxel_encoder(...)
        # é‹è¡Œ middle encoder (PyTorch)
        spatial_features = self._process_middle_encoder(...)
        # é‹è¡Œ backbone/neck/head
        return self._run_backbone_neck_head(...)
```

---

### 2. YOLOX æ¶æ§‹

#### æ–‡ä»¶çµæ§‹
```
projects/YOLOX_opt_elan/deploy/
â”œâ”€â”€ main.py                    # ä¸»ç¨‹åº
â”œâ”€â”€ data_loader.py             # æ•¸æ“šåŠ è¼‰
â”œâ”€â”€ evaluator.py               # è©•ä¼°å™¨
â”œâ”€â”€ onnx_wrapper.py           # ONNX å°å‡ºåŒ…è£å™¨
â””â”€â”€ configs/deploy_config.py   # é…ç½®
```

#### ç‰¹æ®Šéœ€æ±‚
- **å–®å¼•æ“ ONNX**: æ¨™æº–å–®æ–‡ä»¶å°å‡º
- **è¼¸å‡ºæ ¼å¼è½‰æ›**: éœ€è¦ Tier4 å…¼å®¹æ ¼å¼
- **Wrapper æ¨¡å¼**: ä½¿ç”¨åŒ…è£å™¨ä¿®æ”¹è¼¸å‡ºæ ¼å¼

#### å¯¦ç¾æ–¹å¼
```python
# 1. ONNX Wrapper
class YOLOXONNXWrapper(nn.Module):
    def forward(self, x):
        # ç²å–åŸå§‹è¼¸å‡º
        outputs = self.model(x)
        # è½‰æ›ç‚º Tier4 æ ¼å¼
        return self._convert_to_tier4_format(outputs)

# 2. æ¨™æº– Backend ä½¿ç”¨
# ä½¿ç”¨ autoware_ml.deployment.backends.ONNXBackend
# ä½¿ç”¨ autoware_ml.deployment.backends.TensorRTBackend
```

---

### 3. CalibrationStatusClassification æ¶æ§‹

#### æ–‡ä»¶çµæ§‹
```
projects/CalibrationStatusClassification/deploy/
â”œâ”€â”€ main.py                    # ä¸»ç¨‹åº
â”œâ”€â”€ data_loader.py             # æ•¸æ“šåŠ è¼‰
â”œâ”€â”€ evaluator.py               # è©•ä¼°å™¨
â””â”€â”€ configs/deploy_config.py   # é…ç½®
```

#### ç‰¹æ®Šéœ€æ±‚
- **æ¨™æº–å–®å¼•æ“**: æœ€ç°¡å–®çš„éƒ¨ç½²æ¨¡å¼
- **ç„¡ç‰¹æ®Šè™•ç†**: ç›´æ¥ä½¿ç”¨æ¡†æ¶æä¾›çš„ backend

#### å¯¦ç¾æ–¹å¼
```python
# ç›´æ¥ä½¿ç”¨æ¡†æ¶çµ„ä»¶
from autoware_ml.deployment.backends import ONNXBackend, TensorRTBackend
from autoware_ml.deployment.exporters import ONNXExporter, TensorRTExporter

# ç„¡éœ€è‡ªå®šç¾© backend æˆ– helper
```

---

## ğŸ” æ¶æ§‹å·®ç•°åˆ†æ

### å…±åŒé» âœ…

| çµ„ä»¶ | CenterPoint | YOLOX | CalibrationStatus |
|------|-------------|-------|-------------------|
| **ä¸»ç¨‹åºçµæ§‹** | âœ… ç›¸ä¼¼ | âœ… ç›¸ä¼¼ | âœ… ç›¸ä¼¼ |
| **æ•¸æ“šåŠ è¼‰å™¨** | âœ… ç¹¼æ‰¿ BaseDataLoader | âœ… ç¹¼æ‰¿ BaseDataLoader | âœ… ç¹¼æ‰¿ BaseDataLoader |
| **è©•ä¼°å™¨** | âœ… ç¹¼æ‰¿ BaseEvaluator | âœ… ç¹¼æ‰¿ BaseEvaluator | âœ… ç¹¼æ‰¿ BaseEvaluator |
| **é…ç½®ç®¡ç†** | âœ… ä½¿ç”¨ BaseDeploymentConfig | âœ… ä½¿ç”¨ BaseDeploymentConfig | âœ… ä½¿ç”¨ BaseDeploymentConfig |
| **é©—è­‰æµç¨‹** | âœ… ä½¿ç”¨ verify_model_outputs | âœ… ä½¿ç”¨ verify_model_outputs | âœ… ä½¿ç”¨ verify_model_outputs |

### å·®ç•°é» âŒ

| çµ„ä»¶ | CenterPoint | YOLOX | CalibrationStatus |
|------|-------------|-------|-------------------|
| **ONNX å°å‡º** | âŒ è‡ªå®šç¾© Helper | âŒ è‡ªå®šç¾© Wrapper | âœ… æ¨™æº–å°å‡º |
| **TensorRT Backend** | âŒ è‡ªå®šç¾© Backend | âœ… æ¨™æº– Backend | âœ… æ¨™æº– Backend |
| **å¾Œè™•ç†** | âŒ è‡ªå®šç¾© PyTorch decoder | âœ… æ¨™æº–å¾Œè™•ç† | âœ… æ¨™æº–å¾Œè™•ç† |
| **å¤šå¼•æ“æ”¯æŒ** | âŒ ç¡¬ç·¨ç¢¼ | âŒ ä¸æ”¯æŒ | âŒ ä¸æ”¯æŒ |

---

## ğŸš¨ ç•¶å‰å•é¡Œ

### 1. ä»£ç¢¼é‡è¤‡
- **CenterPoint**: è‡ªå®šç¾© `centerpoint_onnx_helper.py` + `centerpoint_tensorrt_backend.py`
- **YOLOX**: è‡ªå®šç¾© `onnx_wrapper.py`
- **CalibrationStatus**: ç„¡è‡ªå®šç¾©ï¼ˆä½†åŠŸèƒ½å—é™ï¼‰

### 2. æ“´å±•æ€§å·®
- æ–°æ¨¡å‹éœ€è¦é‡è¤‡å¯¦ç¾ç›¸ä¼¼åŠŸèƒ½
- ç„¡æ³•å¾©ç”¨å¤šå¼•æ“è™•ç†é‚è¼¯
- å¾Œè™•ç†é‚è¼¯åˆ†æ•£åœ¨å„è™•

### 3. ç¶­è­·å›°é›£
- æ¯å€‹æ¨¡å‹æœ‰è‡ªå·±çš„ç‰¹æ®Šè™•ç†
- æ¡†æ¶æ›´æ–°éœ€è¦åŒæ­¥ä¿®æ”¹å¤šå€‹åœ°æ–¹
- æ¸¬è©¦è¦†è“‹ä¸å®Œæ•´

---

## ğŸ¯ çµ±ä¸€æ¡†æ¶è¨­è¨ˆ

### æ ¸å¿ƒæ¦‚å¿µ

#### 1. Pipeline æ¶æ§‹
```python
class DeploymentPipeline:
    def __init__(self, model_type: str, config: dict):
        self.model_type = model_type
        self.config = config
        self.preprocessor = self._create_preprocessor()
        self.midprocessor = self._create_midprocessor()
        self.postprocessor = self._create_postprocessor()
    
    def process(self, input_data):
        # 1. Preprocessing
        processed_data = self.preprocessor.process(input_data)
        
        # 2. Mid-processing (for multi-engine models)
        if self.midprocessor:
            processed_data = self.midprocessor.process(processed_data)
        
        # 3. Postprocessing
        output = self.postprocessor.process(processed_data)
        return output
```

#### 2. æ¨¡çµ„åŒ– Backend
```python
class ModularBackend(BaseBackend):
    def __init__(self, engines: List[str], processors: Dict[str, Any]):
        self.engines = engines
        self.processors = processors
    
    def infer(self, input_data):
        # æ ¹æ“š engines æ•¸é‡æ±ºå®šè™•ç†æµç¨‹
        if len(self.engines) == 1:
            return self._single_engine_inference(input_data)
        else:
            return self._multi_engine_inference(input_data)
```

#### 3. å¯é…ç½®çš„è™•ç†å™¨
```python
class Preprocessor:
    def __init__(self, config: dict):
        self.config = config
        self.voxelizer = config.get('voxelizer', None)
        self.normalizer = config.get('normalizer', None)
    
    def process(self, input_data):
        # æ ¹æ“šé…ç½®æ‡‰ç”¨ä¸åŒçš„é è™•ç†
        pass

class Midprocessor:
    def __init__(self, config: dict):
        self.config = config
        self.pytorch_model = config.get('pytorch_model', None)
    
    def process(self, input_data):
        # è™•ç†ä¸­é–“æ­¥é©Ÿï¼ˆå¦‚ CenterPoint çš„ middle encoderï¼‰
        pass

class Postprocessor:
    def __init__(self, config: dict):
        self.config = config
        self.decoder = config.get('decoder', None)
        self.nms = config.get('nms', None)
    
    def process(self, input_data):
        # å¾Œè™•ç†ï¼ˆè§£ç¢¼ã€NMS ç­‰ï¼‰
        pass
```

---

## ğŸ—ï¸ å»ºè­°çš„æ–°æ¶æ§‹

### 1. çµ±ä¸€ Backend ç³»çµ±

```python
# autoware_ml/deployment/backends/modular_backend.py
class ModularBackend(BaseBackend):
    """çµ±ä¸€çš„æ¨¡çµ„åŒ– Backendï¼Œæ”¯æŒå–®å¼•æ“å’Œå¤šå¼•æ“"""
    
    def __init__(self, 
                 engines: List[str],
                 preprocessor_config: dict = None,
                 midprocessor_config: dict = None, 
                 postprocessor_config: dict = None):
        self.engines = engines
        self.preprocessor = Preprocessor(preprocessor_config or {})
        self.midprocessor = Midprocessor(midprocessor_config or {}) if midprocessor_config else None
        self.postprocessor = Postprocessor(postprocessor_config or {})
    
    def infer(self, input_data):
        # 1. Preprocessing
        processed_data = self.preprocessor.process(input_data)
        
        # 2. Engine inference
        if len(self.engines) == 1:
            # å–®å¼•æ“æ¨¡å¼
            engine_output = self._run_single_engine(processed_data)
        else:
            # å¤šå¼•æ“æ¨¡å¼
            engine_output = self._run_multi_engines(processed_data)
        
        # 3. Mid-processing (å¦‚æœéœ€è¦)
        if self.midprocessor:
            engine_output = self.midprocessor.process(engine_output)
        
        # 4. Post-processing
        final_output = self.postprocessor.process(engine_output)
        
        return final_output
```

### 2. æ¨¡å‹ç‰¹å®šé…ç½®

```python
# autoware_ml/deployment/configs/model_configs.py
MODEL_CONFIGS = {
    "CenterPoint": {
        "engines": ["pts_voxel_encoder", "pts_backbone_neck_head"],
        "preprocessor": {
            "type": "voxelization",
            "voxel_size": [0.05, 0.05, 0.1],
            "point_cloud_range": [-50, -50, -5, 50, 50, 3]
        },
        "midprocessor": {
            "type": "pytorch_middle_encoder",
            "requires_pytorch_model": True
        },
        "postprocessor": {
            "type": "centerpoint_decoder",
            "requires_pytorch_model": True
        }
    },
    
    "YOLOX": {
        "engines": ["yolox_model"],
        "preprocessor": {
            "type": "image_normalization",
            "mean": [0.485, 0.456, 0.406],
            "std": [0.229, 0.224, 0.225]
        },
        "postprocessor": {
            "type": "yolox_decoder",
            "output_format": "tier4_compatible"
        }
    },
    
    "CalibrationStatusClassification": {
        "engines": ["classification_model"],
        "preprocessor": {
            "type": "image_normalization"
        },
        "postprocessor": {
            "type": "classification_decoder"
        }
    }
}
```

### 3. çµ±ä¸€çš„å°å‡ºå™¨

```python
# autoware_ml/deployment/exporters/modular_exporter.py
class ModularExporter:
    """çµ±ä¸€çš„å°å‡ºå™¨ï¼Œæ”¯æŒä¸åŒæ¨¡å‹çš„ç‰¹æ®Šéœ€æ±‚"""
    
    def __init__(self, model_type: str, config: dict):
        self.model_type = model_type
        self.config = config
        self.model_config = MODEL_CONFIGS[model_type]
    
    def export_onnx(self, pytorch_model, output_path):
        if self.model_type == "CenterPoint":
            return self._export_centerpoint_onnx(pytorch_model, output_path)
        elif self.model_type == "YOLOX":
            return self._export_yolox_onnx(pytorch_model, output_path)
        else:
            return self._export_standard_onnx(pytorch_model, output_path)
    
    def export_tensorrt(self, onnx_path, output_path):
        engines = self.model_config["engines"]
        if len(engines) == 1:
            return self._export_single_engine_trt(onnx_path, output_path)
        else:
            return self._export_multi_engine_trt(onnx_path, output_path)
```

---

## ğŸ“Š æ–°æ¶æ§‹çš„å„ªå‹¢

### 1. ä»£ç¢¼å¾©ç”¨ âœ…
- **Preprocessor**: æ‰€æœ‰æ¨¡å‹å…±äº«é è™•ç†é‚è¼¯
- **Midprocessor**: å¤šå¼•æ“æ¨¡å‹å…±äº«ä¸­é–“è™•ç†
- **Postprocessor**: æ‰€æœ‰æ¨¡å‹å…±äº«å¾Œè™•ç†é‚è¼¯
- **ModularBackend**: çµ±ä¸€çš„æ¨ç†æ¥å£

### 2. æ˜“æ–¼æ“´å±• âœ…
- **æ–°æ¨¡å‹**: åªéœ€æ·»åŠ é…ç½®ï¼Œç„¡éœ€é‡å¯«ä»£ç¢¼
- **æ–°åŠŸèƒ½**: åœ¨å°æ‡‰çš„ processor ä¸­æ·»åŠ 
- **æ–°å¼•æ“**: æ”¯æŒä»»æ„æ•¸é‡çš„å¼•æ“

### 3. ç¶­è­·æ€§ âœ…
- **çµ±ä¸€æ¥å£**: æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç›¸åŒçš„ API
- **é…ç½®é©…å‹•**: è¡Œç‚ºç”±é…ç½®æ–‡ä»¶æ§åˆ¶
- **æ¸¬è©¦å‹å¥½**: æ¯å€‹çµ„ä»¶å¯ä»¥ç¨ç«‹æ¸¬è©¦

### 4. æ€§èƒ½å„ªåŒ– âœ…
- **ç·©å­˜**: å¯ä»¥ç·©å­˜ä¸­é–“çµæœ
- **ä¸¦è¡Œ**: å¤šå¼•æ“å¯ä»¥ä¸¦è¡ŒåŸ·è¡Œ
- **å…§å­˜ç®¡ç†**: çµ±ä¸€çš„å…§å­˜ç®¡ç†ç­–ç•¥

---

## ğŸš€ å¯¦æ–½è¨ˆåŠƒ

### Phase 1: åŸºç¤æ¶æ§‹
1. âœ… å‰µå»º `ModularBackend` é¡
2. âœ… å¯¦ç¾ `Preprocessor`, `Midprocessor`, `Postprocessor`
3. âœ… å‰µå»ºæ¨¡å‹é…ç½®ç³»çµ±

### Phase 2: é·ç§»ç¾æœ‰æ¨¡å‹
1. âœ… é·ç§» CalibrationStatusClassificationï¼ˆæœ€ç°¡å–®ï¼‰
2. âœ… é·ç§» YOLOXï¼ˆä¸­ç­‰è¤‡é›œåº¦ï¼‰
3. âœ… é·ç§» CenterPointï¼ˆæœ€è¤‡é›œï¼‰

### Phase 3: å„ªåŒ–å’Œæ“´å±•
1. âœ… æ€§èƒ½å„ªåŒ–
2. âœ… æ·»åŠ æ›´å¤šé è™•ç†å™¨
3. âœ… æ”¯æŒæ›´å¤šæ¨¡å‹é¡å‹

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### CenterPoint ä½¿ç”¨æ–°æ¶æ§‹
```python
# é…ç½®
config = {
    "model_type": "CenterPoint",
    "engines": ["pts_voxel_encoder.trt", "pts_backbone_neck_head.trt"],
    "preprocessor": {
        "type": "voxelization",
        "voxel_size": [0.05, 0.05, 0.1]
    },
    "midprocessor": {
        "type": "pytorch_middle_encoder",
        "pytorch_model": pytorch_model
    },
    "postprocessor": {
        "type": "centerpoint_decoder",
        "pytorch_model": pytorch_model
    }
}

# å‰µå»º backend
backend = ModularBackend(**config)

# æ¨ç†
output = backend.infer(input_data)
```

### YOLOX ä½¿ç”¨æ–°æ¶æ§‹
```python
# é…ç½®
config = {
    "model_type": "YOLOX",
    "engines": ["yolox_model.trt"],
    "preprocessor": {
        "type": "image_normalization"
    },
    "postprocessor": {
        "type": "yolox_decoder",
        "output_format": "tier4_compatible"
    }
}

# å‰µå»º backend
backend = ModularBackend(**config)

# æ¨ç†
output = backend.infer(input_data)
```

---

## âœ… ç¸½çµ

### ç•¶å‰å•é¡Œ
- âŒ ä»£ç¢¼é‡è¤‡ï¼ˆæ¯å€‹æ¨¡å‹æœ‰è‡ªå·±çš„ helper/backendï¼‰
- âŒ æ“´å±•æ€§å·®ï¼ˆæ–°æ¨¡å‹éœ€è¦é‡å¯«ï¼‰
- âŒ ç¶­è­·å›°é›£ï¼ˆåˆ†æ•£çš„å¯¦ç¾ï¼‰

### å»ºè­°çš„è§£æ±ºæ–¹æ¡ˆ
- âœ… **çµ±ä¸€ Pipeline**: Preprocessor â†’ Midprocessor â†’ Postprocessor
- âœ… **æ¨¡çµ„åŒ– Backend**: æ”¯æŒå–®å¼•æ“å’Œå¤šå¼•æ“
- âœ… **é…ç½®é©…å‹•**: è¡Œç‚ºç”±é…ç½®æ–‡ä»¶æ§åˆ¶
- âœ… **æ˜“æ–¼æ“´å±•**: æ–°æ¨¡å‹åªéœ€æ·»åŠ é…ç½®

### é æœŸæ•ˆæœ
- âœ… **ä»£ç¢¼å¾©ç”¨**: æ¸›å°‘ 70% çš„é‡è¤‡ä»£ç¢¼
- âœ… **æ˜“æ–¼ç¶­è­·**: çµ±ä¸€çš„æ¥å£å’Œå¯¦ç¾
- âœ… **å¿«é€Ÿæ“´å±•**: æ–°æ¨¡å‹é–‹ç™¼æ™‚é–“æ¸›å°‘ 80%
- âœ… **æ€§èƒ½æå‡**: çµ±ä¸€çš„å„ªåŒ–ç­–ç•¥

---

**é€™å€‹çµ±ä¸€æ¡†æ¶å°‡å¤§å¤§æå‡ AutoWare ML deployment çš„å¯ç¶­è­·æ€§å’Œæ“´å±•æ€§ï¼** ğŸ‰

---

**æ—¥æœŸ**: 2025-10-23  
**ç‹€æ…‹**: ğŸ“‹ è¨­è¨ˆå®Œæˆï¼Œå¾…å¯¦æ–½  
**å„ªå…ˆç´š**: ğŸ”¥ é«˜ï¼ˆæ¶æ§‹æ”¹é€²ï¼‰
